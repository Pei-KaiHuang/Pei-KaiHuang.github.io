
<!DOCTYPE HTML>

<html>

<head>
	<title>Pei-Kai Huang</title>
	<meta charset="utf-8" />        
    <meta name="AUTHOR" content="Pei-Kai Huang">
	<meta name="keywords" content="Pei-Kai Huang, deep learning, computer vision, 黄培凯" />
	<meta name="description" content="Pei-Kai Huang (黄培凯)" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link rel="shortcut icon" href="logo.ico">
	<style>
		table{
			border: none;
		}
		table td{
			border: none;
		}
	</style>
</head>
    
 <script type="text/javascript" async="" src="assets/ga.js"></script>




<body bgcolor="#EEEEEE">

<div >

<div id="layout-content">
<div id="toptitle">
<h1>Pei-Kai Huang (黄培凯)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://pei-kaihuang.github.io/"><img src="picture/peikai_huang.jpg" alt="alt text" width="150px" /></a>&nbsp;</td>
<td align="left"><p>PhD Candidate<br />
<a href="https://">Multimedia Processing Laboratory (MP Lab)</a>, <br />
<a href="https://dcs.site.nthu.edu.tw/">Department of Computer Science</a>,  <br />
<a href="https://www.nthu.edu.tw/">National Tsing Hua University</a>, <br />
101, Section 2, Kuang-Fu Road, Hsinchu, TaiWan<br />
Postcode: 30013 <br />
Email: <a href= "mailto:alwayswithme@gapp.nthu.edu.tw">alwayswithme@gapp.nthu.edu.tw</a>  <br />
<br />
<a href="https://scholar.google.com/citations?user=T0hELCEAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/Pei-KaiHuang">[GitHub]
	 <a href="https://dblp.org/pid/320/2231.html">[dblp]
</td></tr></table>
<h2>About me</h2>
<p>I am currently a Phd Candidate at National Tsing Hua University. 
	I've received the bachelor degree from Fujian Normal University in 2017, and the master degree from National Central University in 2019.
	</p> 
<p>My research area focuses on face anti-spoofing and rPPG Estimation.</p>
<p>As the first author, I have been published in prestigious conferences in the field of computer vision, including CVPR, BMVC, ICME, ICIP, and ACPR. </p>
<p> I have reviewed papers from different CV/AI conferences, e.g., CVPR, ECCV, AAAI, ICME, BMVC, and ICIP, and biomedical related journals, e.g., TIFS, TIM, TBME, BSPC. </p>
</td></tr></table>

 
	<a name="publication"><h3>Publications</h3></a> 
	<hr />
<!-- paper 8 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2024CVPR"><img src="picture/papers/2024_CVPR.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>One-Class Face Anti-spoofing via Spoof Cue Map-Guided Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>;  Cheng-Hsuan Chiang;  Tzu-Hsien Chen; Jun-Xiong Chong; Tyng-Luh Liu; Chiou-Ting Hsu<br>
	  
		       <a href="https://cvpr.thecvf.com/Conferences/2024" style="color:#000000;">The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024, Seattle WA, USA.</a>, [h5-index:422,  
			 <a href="-" style="color:#000000;">CORE Rank A*</a>,
			CCF A, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank A</a> ]
			<br>
		 Paper  | 
		 Code  | 
		 Video  	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 

 <!-- paper 7 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022BMVC"><img src="picture/papers/2023_BMVC.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Test-Time Adaptation for Robust Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>; Chen-Yu Lu;  Shu-Jung Chang; Jun-Xiong Chong; Chiou-Ting Hsu<br>
	  
		       <a href="https://bmvc2023.org/" style="color:#000000;">British Machine Vision Conference (BMVC), 2023, Aberdeen, UK</a>, [h5-index:75,  
			 <a href="http://portal.core.edu.au/conf-ranks/?search=BMVC&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://papers.bmvc2023.org/0379.pdf" style="color:#000000;">Paper</a> | 
		 <a href="https://github.com/Pei-KaiHuang/TTA-FAS" style="color:#000000;">Code</a> | 
		   <a href="https://www.bilibili.com/video/BV1fN4y1r7yL/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
  

	
 <!-- paper 6 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023_ICIP_FAS"><img src="picture/papers/2023_ICIP_FAS.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i> LDCformer: Incorporating Learnable Descriptive Convolution to Vision Transformer for Face Anti-Spoofing </i>
			<br> 
	      <b>Pei-Kai Huang</b>; Cheng-Hsuan Chiang; Jun-Xiong Chong; Tzu-Hsien Chen; Hui-Yu Ni; Chiou-Ting Hsu <br> 
		  <a href="https://2023.ieeeicip.org/" style="color:#000000;">IEEE International Conference on Image Processing (ICIP), 2023, Kuala Lumpur, Malaysia</a>,
                 [h5-index:60,
		 <a href="http://portal.core.edu.au/conf-ranks/?search=ICIP&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank B</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222330" style="color:#000000;">Paper</a> |
		 <a href="https://github.com/Pei-KaiHuang/ICIP23_D-LDCformer" style="color:#000000;">Code</a> |
		  <a href="https://www.bilibili.com/video/BV1Wh4y1M75d/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 <!-- paper 5 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023ICIP_Seg"><img src="picture/papers/2023_ICIP_Seg.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>  Single-Domain Generalization for Semantic Segmentation via Dual-level Domain Augmentation </i>
			<br>
		   Shu-Jung Chang*; Chen-Yu Lu*;  <b>Pei-Kai Huang*</b>; Chiou-Ting Hsu (* equal contribution)<br> 
	  
		<a href="https://2023.ieeeicip.org/" style="color:#000000;">IEEE International Conference on Image Processing (ICIP), 2023, Kuala Lumpur, Malaysia</a>, 
			[h5-index:60, 
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICIP&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank B</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222684" style="color:#000000;">Paper</a> |
		  <a href="https://www.bilibili.com/video/BV1Nw411U7Qv/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
			  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
 <!-- paper 4 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023ICME"><img src="picture/papers/2023_ICME.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Towards Diverse Liveness Feature Representation and Domain Expansion for Cross-Domain Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>; Jun-Xiong Chong; Hui-Yu Ni; Tzu-Hsien Chen; Chiou-Ting Hsu<br>
	  
		  <a href="https://www.2023.ieeeicme.org/" style="color:#000000;">IEEE International Conference on Multimedia & Expo (ICME), 2023, Brisbane, Australia</a>, [h5-index:40,
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICME&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220051" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/Jxchong1999/DFANet" style="color:#000000;">Code</a> | 
		 <a href="https://www.bilibili.com/video/BV1Y8411D7DA/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  | 
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_ICME_poster.pdf" style="color:#000000;" >Poster</a> 
			  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 
 <!-- paper 3 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022BMVC"><img src="picture/papers/2022_BMVC.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Learnable Descriptive Convolutional Network for Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>; Hui-Yu Ni; Yan-Qin Ni; Chiou-Ting Hsu<br>
	  
		       <a href="https://bmvc2022.org/" style="color:#000000;">British Machine Vision Conference (BMVC), 2022, London, UK</a>, [h5-index:75, 
			<a href="http://portal.core.edu.au/conf-ranks/?search=BMVC&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF C,   <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		  <a href="https://bmvc2022.mpi-inf.mpg.de/0239.pdf" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/huiyu8794/LDCNet" style="color:#000000;">Code</a> | 
		  <a href="https://www.bilibili.com/video/BV1Wd4y1n7rd/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  |
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2022_BMVC_poster.pdf" style="color:#000000;" >Poster</a> 	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
 
 
 <!-- paper 2 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022ICME"><img src="picture/papers/2022_ICME.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Learning to Augment Face Presentation Attack Dataset via Disentangled Feature Learning from Limited Spoof Data  </i>
			<br>
		    <b>Pei-Kai Huang</b>; Chu-Ling Chang; Hui-Yu Ni; Chiou-Ting Hsu<br>
	  
		  <a href="https://2022.ieeeicme.org/" style="color:#000000;"> IEEE International Conference on Multimedia & Expo (ICME), 2022, Taipei, Taiwan</a>, [h5-index:40,
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICME&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859657" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV11M411e7YP/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
			  
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 
 
 
 	<!-- paper 1 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2021ACPR"><img src="picture/papers/2021_ACPR.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Face Anti-Spoofing via Robust Auxiliary Estimation and Discriminative Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>; Ming-Chieh Chin; Chiou-Ting Hsu<br>
	  
		   <a href="https://brain.korea.ac.kr/acpr/" style="color:#000000;">  Asian Conference on Pattern Recognition (ACPR), 2021, Ieju Island, Korea</a>, [h5-index:15, indexed by EI]
			<br>
		  <a href="https://link.springer.com/chapter/10.1007/978-3-031-02375-0_33" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV1tx4y1j7Af/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
			
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 


<br><br>                                                                                                
	<a name="publication"><h3> </h3></a>
	<hr />

</div>

<div id="footer">
<div id="footer-text">
<br>Last updated：2024/02/28, by <a href= "mailto:alwayswithme@gapp.nthu.edu.tw">Pei-Kai Huang </a>.
</div>
</div>

</body>
</html>
