
<!DOCTYPE HTML>

<html>

<head>
	<title>Pei-Kai Huang</title>
	<meta charset="utf-8" />        
    <meta name="AUTHOR" content="Pei-Kai Huang">
	<meta name="keywords" content="Pei-Kai Huang, deep learning, computer vision, 黄培凯" />
	<meta name="description" content="Peikai Huang (Pei-Kai Huang, 黄培凯)" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link rel="shortcut icon" href="logo.ico">
	<style>
		table{
			border: none;
		}
		table td{
			border: none;
		}
	</style>
</head>
    
 <script type="text/javascript" async="" src="assets/ga.js"></script>




<body bgcolor="#EEEEEE">

<div >

<div id="layout-content">
<div id="toptitle">
<h1>Peikai Huang (Pei-Kai Huang, 黄培凯)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://pei-kaihuang.github.io/"><img src="picture/peikai_huang.jpg" alt="alt text" width="150px" /></a>&nbsp;</td>
<td align="left"><p>PhD Candidate<br />
<a href="https://">Multimedia Processing Laboratory (MP Lab)</a>, <br />
<a href="https://dcs.site.nthu.edu.tw/">Department of Computer Science</a>,  <br />
<a href="https://www.nthu.edu.tw/">National Tsing Hua University</a>, <br />
101, Section 2, Kuang-Fu Road, Hsinchu, Taiwan<br />
Postcode: 30013 <br />
Email: <a href= "mailto:alwayswithme@gapp.nthu.edu.tw">alwayswithme@gapp.nthu.edu.tw</a>  <br />
<br />
<a href="https://scholar.google.com/citations?user=T0hELCEAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/Pei-KaiHuang">[GitHub]
	 <a href="https://dblp.org/pid/320/2231.html">[dblp]
</td></tr></table>
<h2>About me</h2> 
<p>
   I am about to return to my alma mater, Fujian Normal University, for a faculty position.  
   I am currently a Phd Candidate at National Tsing Hua University. 
   I've received the bachelor degree from Fujian Normal University in 2017, and the master degree from National Central University in 2019.
   I live in Xiamen, China. 
</p>	 
<p>My research area focuses on face anti-spoofing and rPPG Estimation.As the first author, I have been published in prestigious conferences in the field of computer vision, including CVPR, AAAI, BMVC, ICME, ICIP, and ACPR, as well as in renowned journals, including Information Science and ATSIP.  </p>
<p> I have reviewed papers from different CV/AI conferences, e.g., CVPR, ECCV, AAAI, ACM MM, ICME, BMVC, and ICIP, and biomedical related journals, e.g., TIFS, TIM, TBME, BSPC. </p>
</td></tr></table>


<a name="publication"><h3>Preprint</h3></a> 
	<hr />
<!-- paper J04 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2025PR_rPPG_TTA"><img src="picture/papers/2025PR_rPPG_TTA.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Fully Test-Time rPPG Estimation via Synthetic Signal-Guided Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>, Tzu-Hsien Chena, Ya-Ting Chana, Kuan-Wen Chena, Shih-Yu Yanga, Yen-Chun Choua, Chiou-Ting Hsu<br>
	  
		       Pattern Recognition, (Major revision) , [中科院一区Top, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a>, SCIE:Q1, IF:7.5, h-index:180]
			<br>
		  Paper  |   Code |
			Video
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
	
<!-- paper J03 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2025PR_LDCformer"><img src="picture/papers/2025_PR_LDCformer.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Enhancing Learnable Descriptive Convolutional Vision Transformer for Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Chiou-Ting Hsu<br>
	  
		       Pattern Recognition, (Major revision) , [中科院一区Top, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a>, SCIE:Q1, IF:7.5, h-index:180]
			<br>
		  Paper  |  
		 <a href="https://github.com/Pei-KaiHuang/LDCformer_Ext" style="color:#000000;">Code</a> |
			Video
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
 
<!-- paper J04 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2025PR_LDCformer"><img src="picture/papers/2025_TIFS_DDrPPG.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>DD-rPPGNet: De-interfering and Descriptive Feature Learning for Unsupervised rPPG Estimation</i>
			<br>
		    <b>Pei-Kai Huang</b>, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Chiou-Ting Hsu<br>
	  
		       IEEE Transactions on Information Forensics & Security (TIFS), (Accept with mandatory minor revision) , [中科院一区Top, CCF A,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank A</a>, SCIE:Q1, IF:6.3, h-index:95]
			<br>
		  Paper  |  Code|
			Video
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
	

	<a name="publication"><h3>Publications (Journal)</h3></a> 
	<hr />
<!-- paper J02 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2024IS_CDformer"><img src="picture/papers/2024_Information Science.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Channel difference transformer for face anti-spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Chiou-Ting Hsu<br>
	  
		       Information Sciences, 2025 [中科院二区, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> , SCIE:Q1]
			<br>
		  <a href="https://www.sciencedirect.com/science/article/pii/S0020025525000362" style="color:#000000;">Paper</a>    | 
		<a href="https://github.com/Pei-KaiHuang/CDformer" style="color:#000000;">Code</a> 
		    
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
<!-- paper J01 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2024_ATSIP.png"><img src="picture/papers/2024_ATSIP.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>A Survey on Deep Learning-based Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Cheng-Hsuan Chiang, Tzu-Hsien Chen,  Chiou-Ting Hsu<br>
	  
		      APSIPA Transactions on Signal and Information Processing, 2024 [中科院三区, ESCI:Q1, IF:3.2, h-index:25]
			<br>
		  <a href="https://www.nowpublishers.com/article/OpenAccessDownload/SIP-20240053" style="color:#000000;">Paper</a>    
		    
		</div>
	</td>
	</tr></tbody></table> 
 <br> 



	
	<a name="publication"><h3>Publications (Conference)</h3></a> 
	<hr />
<!-- paper C09 -->
<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2025AAAI"><img src="picture/papers/2025_AAAI.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>SLIP: Spoof-aware one-class face anti-spoofing with Language Image Pretraining</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Cheng-Hsuan Chiang, Tzu-Hsien Chen, Tyng-Luh Liu, Chiou-Ting Hsu.<br>
	  
		     The 39th Annual AAAI Conference on Artificial Intelligence (AAAI), 2025, USA. , [<a href="-" style="color:#000000;">CORE Rank A*</a>,
			CCF A, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank A</a> ]
			<br>
		 Paper  | 
		<a href="https://github.com/Pei-KaiHuang/AAAI25-SLIP" style="color:#000000;">Code</a> |
         <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2025_AAAI_poster.pdf" style="color:#000000;" >Poster</a>		 
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
<!-- paper 8 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2024CVPR"><img src="picture/papers/2024_CVPR.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>One-Class Face Anti-spoofing via Spoof Cue Map-Guided Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>,  Cheng-Hsuan Chiang,  Tzu-Hsien Chen, Jun-Xiong Chong, Tyng-Luh Liu, Chiou-Ting Hsu<br>
	  
		      The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024, Seattle WA, USA.</a>, [h5-index:422,  
			 <a href="-" style="color:#000000;">CORE Rank A*</a>,
			CCF A, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank A</a> ]
			<br>
		  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_One-Class_Face_Anti-spoofing_via_Spoof_Cue_Map-Guided_Feature_Learning_CVPR_2024_paper.pdf" style="color:#000000;">Paper</a>  | 
		 <a href="https://github.com/Pei-KaiHuang/CVPR24_OC_SCMNet" style="color:#000000;">Code</a> |
		  <a href="https://www.bilibili.com/video/BV1Lw4m1Q7fK/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a> |
			<a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2024_CVPR_poster.pdf" style="color:#000000;" >Poster</a>	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 

 <!-- paper 7 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022BMVC"><img src="picture/papers/2023_BMVC.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Test-Time Adaptation for Robust Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Chen-Yu Lu,  Shu-Jung Chang, Jun-Xiong Chong, Chiou-Ting Hsu<br>
	  
		       British Machine Vision Conference (BMVC), 2023, Aberdeen, UK</a>, [h5-index:75,  
			 <a href="http://portal.core.edu.au/conf-ranks/?search=BMVC&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://papers.bmvc2023.org/0379.pdf" style="color:#000000;">Paper</a> | 
		 <a href="https://github.com/Pei-KaiHuang/TTA-FAS" style="color:#000000;">Code</a> | 
		   <a href="https://www.bilibili.com/video/BV1fN4y1r7yL/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
			| <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_BMVC_poster.pdf" style="color:#000000;" >Poster</a>
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
  

	
 <!-- paper 6 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023_ICIP_FAS"><img src="picture/papers/2023_ICIP_FAS.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i> LDCformer: Incorporating Learnable Descriptive Convolution to Vision Transformer for Face Anti-Spoofing </i>
			<br> 
	      <b>Pei-Kai Huang</b>, Cheng-Hsuan Chiang, Jun-Xiong Chong, Tzu-Hsien Chen, Hui-Yu Ni, Chiou-Ting Hsu <br> 
		  IEEE International Conference on Image Processing (ICIP), 2023, Kuala Lumpur, Malaysia</a>,
                 [h5-index:60,
		 <a href="http://portal.core.edu.au/conf-ranks/?search=ICIP&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank B</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222330" style="color:#000000;">Paper</a> |
		 <a href="https://github.com/Pei-KaiHuang/ICIP23_D-LDCformer" style="color:#000000;">Code</a> |
		  <a href="https://www.bilibili.com/video/BV1Wh4y1M75d/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
		| <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_ICIP_poster.pdf" style="color:#000000;" >Poster</a>
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 <!-- paper 5 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023ICIP_Seg"><img src="picture/papers/2023_ICIP_Seg.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>  Single-Domain Generalization for Semantic Segmentation via Dual-level Domain Augmentation </i>
			<br>
		   Shu-Jung Chang*, Chen-Yu Lu*,  <b>Pei-Kai Huang*</b>, Chiou-Ting Hsu (* equal contribution)<br> 
	  
		 IEEE International Conference on Image Processing (ICIP), 2023, Kuala Lumpur, Malaysia</a>, 
			[h5-index:60, 
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICIP&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank B</a>,
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222684" style="color:#000000;">Paper</a> |
		  <a href="https://www.bilibili.com/video/BV1Nw411U7Qv/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
		 | Oral	  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
 <!-- paper 4 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2023ICME"><img src="picture/papers/2023_ICME.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Towards Diverse Liveness Feature Representation and Domain Expansion for Cross-Domain Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Hui-Yu Ni, Tzu-Hsien Chen, Chiou-Ting Hsu<br>
	  
		   IEEE International Conference on Multimedia & Expo (ICME), 2023, Brisbane, Australia</a>, [h5-index:40,
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICME&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220051" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/Jxchong1999/DFANet" style="color:#000000;">Code</a> | 
		 <a href="https://www.bilibili.com/video/BV1Y8411D7DA/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  | 
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_ICME_poster.pdf" style="color:#000000;" >Poster</a> 
			  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 
 <!-- paper 3 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022BMVC"><img src="picture/papers/2022_BMVC.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Learnable Descriptive Convolutional Network for Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>, Hui-Yu Ni, Yan-Qin Ni, Chiou-Ting Hsu<br>
	  
		       British Machine Vision Conference (BMVC), 2022, London, UK</a>, [h5-index:75, 
			<a href="http://portal.core.edu.au/conf-ranks/?search=BMVC&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF C,   <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a> ]
			<br>
		  <a href="https://bmvc2022.mpi-inf.mpg.de/0239.pdf" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/huiyu8794/LDCNet" style="color:#000000;">Code</a> | 
		  <a href="https://www.bilibili.com/video/BV1Wd4y1n7rd/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  |
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2022_BMVC_poster.pdf" style="color:#000000;" >Poster</a> 	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
 
 
 <!-- paper 2 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2022ICME"><img src="picture/papers/2022_ICME.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Learning to Augment Face Presentation Attack Dataset via Disentangled Feature Learning from Limited Spoof Data  </i>
			<br>
		    <b>Pei-Kai Huang</b>, Chu-Ling Chang, Hui-Yu Ni, Chiou-Ting Hsu<br>
	  
		  IEEE International Conference on Multimedia & Expo (ICME), 2022, Taipei, Taiwan</a>, [h5-index:40,
			 <a href="http://portal.core.edu.au/conf-ranks/?search=ICME&by=all&source=CORE2023&sort=atitle&page=1" style="color:#000000;">CORE Rank A</a>,
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859657" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV11M411e7YP/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
		| Oral		  
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 
 
 
 	<!-- paper 1 -->
	<table><tbody><tr>
	<td valign="top" align="center" width="220" id="2021ACPR"><img src="picture/papers/2021_ACPR.png" width="200" height="100" border="0">
	</td>
	<td>
		<div align="left">
			<i>Face Anti-Spoofing via Robust Auxiliary Estimation and Discriminative Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>, Ming-Chieh Chin, Chiou-Ting Hsu<br>
	  
		   Asian Conference on Pattern Recognition (ACPR), 2021, Ieju Island, Korea</a>, [h5-index:15, indexed by EI]
			<br>
		  <a href="https://link.springer.com/chapter/10.1007/978-3-031-02375-0_33" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV1tx4y1j7Af/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
		| Oral		
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 


<br><br>                                                                                                
	<a name="publication"><h3> </h3></a>
	<hr />

</div>

<div id="footer">
<div id="footer-text">
<br>Last updated：2025/03/19, by <a href= "mailto:alwayswithme@gapp.nthu.edu.tw">Pei-Kai Huang </a>. <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">Pageviews:<span id="busuanzi_value_site_pv"></span></span>
</div>
</div>



</body>
</html>
