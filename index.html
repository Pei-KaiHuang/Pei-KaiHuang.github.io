
<!DOCTYPE HTML>

<html>

<head>
	<title>Pei-Kai Huang</title>
	<meta charset="utf-8" />        
    <meta name="AUTHOR" content="Pei-Kai Huang">
	<meta name="keywords" content="Pei-Kai Huang, deep learning, computer vision, 黄培凯" />
	<meta name="description" content="Peikai Huang (Pei-Kai Huang, 黄培凯)" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link rel="shortcut icon" href="logo.ico">
	<style>
		table{
			border: none;
		}
		table td{
			border: none;
		}
	</style>
</head>
    
 <script type="text/javascript" async="" src="assets/ga.js"></script>




<body bgcolor="#EEEEEE">

<div >

<div id="layout-content">
<div id="toptitle">
<h1>Peikai Huang (Pei-Kai Huang, 黄培凯)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://pei-kaihuang.github.io/"><img src="picture/pk_daughter.jpg" alt="alt text" width="150px" /></a>&nbsp;</td> 
<td align="left"> 
 ←←← My very cute~cute~cute~ daughter & me   <br />
<a href="https://">Multimedia Processing Laboratory (MP Lab)</a>, <br />
<a href="https://dcs.site.nthu.edu.tw/">Department of Computer Science</a>,  <br />
<a href="https://www.nthu.edu.tw/">National Tsing Hua University</a>, <br />
101, Section 2, Kuang-Fu Road, Hsinchu, Taiwan<br />
Postcode: 30013 <br />
Email: <a href= "mailto:alwayswithme@fjnu.edu.cn">alwayswithme@fjnu.edu.cn</a>  <br />
	    <a href= "mailto:alwayswithme@gapp.nthu.edu.tw">alwayswithme@gapp.nthu.edu.tw</a> 
<br />
<a href="https://orcid.org/0000-0002-5198-5386">[ORCiD]</a>
<a href="https://scholar.google.com/citations?user=T0hELCEAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/Pei-KaiHuang">[GitHub]</a>
	 <a href="https://dblp.org/pid/320/2231.html">[dblp]</a>
</td></tr></table>
<h2>About me</h2> 
<!-- paper J03 
<p>
   I will return to my alma mater, Fujian Normal University, for a faculty position.   
</p>

<p>I've received the Ph.D. degree from National Tsing Hua University in 2025, the master degree from National Central University in 2019, and the bachelor degree from Fujian Normal University in 2017.
   I live in Xiamen and Fuzhou, China. </p>

-->
	
<p>My research area focuses on face anti-spoofing and rPPG Estimation. As the first author, I have been published in prestigious conferences in the field of computer vision, including CVPR, AAAI, BMVC, ICME, ICIP, and ACPR, as well as in renowned journals, including TIFS, Pattern Recognition, Information Science, and ATSIP.  </p>
<p> I have reviewed papers from different CV/AI conferences, e.g., CVPR, ECCV, AAAI, ACM MM, ICME, BMVC, and ICIP, and biomedical related journals, e.g., TIFS, TIM, TBME, BSPC. </p>
<p> <b>If you are interested in pursuing a PhD at National Tsinghua University, National Taiwan University, National Yang Ming Chiao Tung University, National Cheng Kung University, National Central University, please contact me. I would be happy to introduce you to a professor.
</b>
</p>
</td></tr></table>

<a name="Preprint"><h3>News</h3></a> 
<hr />  
[2025/07] One paper was accepted by Pattern Recognition (PR) (CCF B, Top Q1)<br>
[2025/04] One paper was accepted by IEEE Transactions on Information Forensics & Security (TIFS) (CCF A, Top Q1)<br>
[2025/01] One paper was accepted by Information Sciences (CCF B, Q1)<br>
[2024/12] Offered a faculty position at Fujian Normal University <br>
[2024/12] One paper was accepted by AAAI 2025 (CCF A)<br>	
[2024/02] One paper was accepted by CVPR 2024 (CCF A)<br>	
[2023/08] One paper was accepted by BMVC 2023 (CCF C)<br>	
[2023/06] Two papers were accepted by ICIP 2023 (CCF C)<br>	
[2023/03] One paper was accepted by ICME 2023 (CCF B)<br>
[2022/10] One paper was accepted by BMVC 2022 (CCF C)<br>	
[2022/03] One paper was accepted by ICME 2022 (CCF B)<br>	
[2021/08] One paper was accepted by ACPR 2021 <br>	


<a name="Preprint"><h3>Preprint</h3></a> 
	<hr />
<!-- paper J03 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Enhancing Learnable Descriptive Convolutional Vision Transformer for Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Chiou-Ting Hsu<br>
	  
		       <span style="color: #FF0000;"> Pattern Recognition, (Major revision) </span >, [中科院一区Top, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">TH-CPL Rank B</a>, SCIE:Q1, IF:7.5, h-index:180]
			<br>
		  <a href="https://arxiv.org/pdf/2503.22936" style="color:#000000;">Paper</a>  |  
		 <a href="https://github.com/Pei-KaiHuang/LDCformer_Ext" style="color:#000000;">Code</a>
	
		</div>
	</td>
	</tr></tbody></table> 
 <br>  



<!-- paper JXX -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Multi-Modal Face Anti-Spoofing via Cross-Modal Feature Transitions</i>
			<br>
		    Jun-Xiong Chong, Fang-Yu Hsu, Ming-Tsung Hsu, Yi-Ting Lin, Kai-Heng Chien, Chiou-Ting Hsu,<b>Pei-Kai Huang *</b> (* corresponding author) <br>
	  
		   <span style="color: #FF0000;">  Expert Systems with Applications, (Major revision) </span >, [中科院一区Top, CCF B, SCIE:Q1]
			<br>
		   <a href="https://arxiv.org/abs/2507.05575" style="color:#000000;">Paper</a>  | 
			 Code  
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
		

	
<!-- paper J202507 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction</i>
			<br>
		    <b>Pei-Kai Huang</b>, Ya-Ting Chan, Kuan-Wen Chen, Yen-Chun Chou, Shih-Yu Yang, Chiou-Ting Hsu<br>
	           Under review
			<br>
		  <a href="https://arxiv.org/abs/2506.22078" style="color:#000000;">Paper</a>  |  
		 <a>Code</a>
	
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
	
	

 


<!-- paper JXX -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Hao-Chiang Shao, Chiou-Ting Hsu<br>
	  
		       Under review
			<br>
		   <a href="https://arxiv.org/pdf/2503.22929" style="color:#000000;">Paper</a>  | 
			 Code  
			
		</div>
	</td>
	</tr></tbody></table> 
 <br>  


	<a name="publication"><h3>Publications (Journal)</h3></a> 
	<hr />
<!-- paper J04 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Fully Test-Time rPPG Estimation via Synthetic Signal-Guided Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Shih-Yu Yang, Yen-Chun Chou, Chiou-Ting Hsu<br>
	  
		      <span style="color: #FF0000;"> Pattern Recognition </span >, 2026 , [中科院一区Top, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a>, SCIE:Q1 ]
			<br>
		  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325007629" style="color:#000000;">Paper</a>  |   <a href="https://github.com/Pei-KaiHuang/Pattern-Recognition-25-TTA-rPPG" style="color:#000000;">Code</a>  
			
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
	
<!-- paper J04 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>DD-rPPGNet: De-interfering and Descriptive Feature Learning for Unsupervised rPPG Estimation</i>
			<br>
		    <b>Pei-Kai Huang</b>, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Chiou-Ting Hsu<br>
	  
		       <span style="color: #FF0000;"> IEEE Transactions on Information Forensics & Security (TIFS) </span >, 2025 , [中科院一区Top, CCF A,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) A</a>, SCIE:Q1 ]
			<br>
		   <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10981460" style="color:#000000;">Paper</a>  | 
			<a href="https://github.com/Pei-KaiHuang/TIFS2025-DD-rPPGNet" style="color:#000000;">Code</a> 
			 
			
		</div>
	</td>
	</tr></tbody></table> 
 <br>  
	
	
<!-- paper J02 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Channel difference transformer for face anti-spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Chiou-Ting Hsu<br>
	  
		      <span style="color: #FF0000;">  Information Sciences </span >, 2025 [中科院二区, CCF B,<a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a> , SCIE:Q1]
			<br>
		  <a href="https://www.sciencedirect.com/science/article/pii/S0020025525000362" style="color:#000000;">Paper</a>    | 
		<a href="https://github.com/Pei-KaiHuang/CDformer" style="color:#000000;">Code</a> 
		    
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
<!-- paper J01 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>A Survey on Deep Learning-based Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Ming-Tsung Hsu,  Fang-Yu Hsu, Cheng-Hsuan Chiang, Tzu-Hsien Chen,  Chiou-Ting Hsu<br>
	  
		     <span style="color: #FF0000;"> APSIPA Transactions on Signal and Information Processing </span >, 2024 [中科院三区, ESCI:Q1 ]
			<br>
		  <a href="https://www.nowpublishers.com/article/OpenAccessDownload/SIP-20240053" style="color:#000000;">Paper</a>    
		    
		</div>
	</td>
	</tr></tbody></table> 
 <br> 



	
	<a name="publication"><h3>Publications (Conference)</h3></a> 
	<hr /> 
<!-- paper C09 -->
<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>SLIP: Spoof-aware one-class face anti-spoofing with Language Image Pretraining</i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Cheng-Hsuan Chiang, Tzu-Hsien Chen, Tyng-Luh Liu, Chiou-Ting Hsu.<br>
	  
		     <span style="color: #FF0000;">The 39th Annual AAAI Conference on Artificial Intelligence (AAAI) </span >, 2025, USA. , [ 
			CCF A, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) A</a> ]
			<br>
		 <a href="https://ojs.aaai.org/index.php/AAAI/article/download/32385/34540" style="color:#000000;">Paper</a>   | 
		<a href="https://github.com/Pei-KaiHuang/AAAI25-SLIP" style="color:#000000;">Code</a> |
         <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2025_AAAI_poster.pdf" style="color:#000000;" >Poster</a>		 
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
<!-- paper 8 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>One-Class Face Anti-spoofing via Spoof Cue Map-Guided Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>,  Cheng-Hsuan Chiang,  Tzu-Hsien Chen, Jun-Xiong Chong, Tyng-Luh Liu, Chiou-Ting Hsu<br>
	  
		      <span style="color: #FF0000;"> The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </span >, 2024, Seattle WA, USA.</a>, [ 
			CCF A, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) A</a> ]
			<br>
		  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_One-Class_Face_Anti-spoofing_via_Spoof_Cue_Map-Guided_Feature_Learning_CVPR_2024_paper.pdf" style="color:#000000;">Paper</a>  | 
		 <a href="https://github.com/Pei-KaiHuang/CVPR24_OC_SCMNet" style="color:#000000;">Code</a> |
		  <a href="https://www.bilibili.com/video/BV1Lw4m1Q7fK/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a> |
			<a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2024_CVPR_poster.pdf" style="color:#000000;" >Poster</a>	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 

 <!-- paper 7 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Test-Time Adaptation for Robust Face Anti-Spoofing</i>
			<br>
		    <b>Pei-Kai Huang</b>, Chen-Yu Lu,  Shu-Jung Chang, Jun-Xiong Chong, Chiou-Ting Hsu<br>
	  
		       <span style="color: #FF0000;"> British Machine Vision Conference (BMVC) </span >, 2023, Aberdeen, UK</a>, [ 
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a> ]
			<br>
		 <a href="https://papers.bmvc2023.org/0379.pdf" style="color:#000000;">Paper</a> | 
		 <a href="https://github.com/Pei-KaiHuang/TTA-FAS" style="color:#000000;">Code</a> | 
		   <a href="https://www.bilibili.com/video/BV1fN4y1r7yL/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
			| <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_BMVC_poster.pdf" style="color:#000000;" >Poster</a>
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
  

	
 <!-- paper 6 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i> LDCformer: Incorporating Learnable Descriptive Convolution to Vision Transformer for Face Anti-Spoofing </i>
			<br> 
	      <b>Pei-Kai Huang</b>, Cheng-Hsuan Chiang, Jun-Xiong Chong, Tzu-Hsien Chen, Hui-Yu Ni, Chiou-Ting Hsu <br> 
		 <span style="color: #FF0000;"> IEEE International Conference on Image Processing (ICIP) </span >, 2023, Kuala Lumpur, Malaysia</a>,
                 [ 
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222330" style="color:#000000;">Paper</a> |
		 <a href="https://github.com/Pei-KaiHuang/ICIP23_D-LDCformer" style="color:#000000;">Code</a> |
		  <a href="https://www.bilibili.com/video/BV1Wh4y1M75d/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
		| <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_ICIP_poster.pdf" style="color:#000000;" >Poster</a>
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 <!-- paper 5 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>  Single-Domain Generalization for Semantic Segmentation via Dual-level Domain Augmentation </i>
			<br>
		   Shu-Jung Chang*, Chen-Yu Lu*,  <b>Pei-Kai Huang*</b>, Chiou-Ting Hsu (* equal contribution)<br> 
	  
		 <span style="color: #FF0000;">IEEE International Conference on Image Processing (ICIP) </span >, 2023, Kuala Lumpur, Malaysia</a>, 
			[ 
			CCF C, <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a> ]
			<br>
		 <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10222684" style="color:#000000;">Paper</a> |
		  <a href="https://www.bilibili.com/video/BV1Nw411U7Qv/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>   
		 | Oral	  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
 <!-- paper 4 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Towards Diverse Liveness Feature Representation and Domain Expansion for Cross-Domain Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>, Jun-Xiong Chong, Hui-Yu Ni, Tzu-Hsien Chen, Chiou-Ting Hsu<br>
	  
		  <span style="color: #FF0000;">  IEEE International Conference on Multimedia & Expo (ICME) </span >, 2023, Brisbane, Australia</a>, [  
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220051" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/Jxchong1999/DFANet" style="color:#000000;">Code</a> | 
		 <a href="https://www.bilibili.com/video/BV1Y8411D7DA/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  | 
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2023_ICME_poster.pdf" style="color:#000000;" >Poster</a> 
			  
		</div>
	</td>
	</tr></tbody></table> 
 <br>   	
	
	
 
 <!-- paper 3 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Learnable Descriptive Convolutional Network for Face Anti-Spoofing </i>
			<br>
		    <b>Pei-Kai Huang</b>, Hui-Yu Ni, Yan-Qin Ni, Chiou-Ting Hsu<br>
	  
		       <span style="color: #FF0000;"> British Machine Vision Conference (BMVC)</span >, 2022, London, UK</a>, [  
			CCF C,   <a href="https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf" style="color:#000000;">Tsinghua (清华) B</a> ]
			<br>
		  <a href="https://bmvc2022.mpi-inf.mpg.de/0239.pdf" style="color:#000000;">Paper</a> | 
		  <a href="https://github.com/huiyu8794/LDCNet" style="color:#000000;">Code</a> | 
		  <a href="https://www.bilibili.com/video/BV1Wd4y1n7rd/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  |
		  <a download href="https://github.com/Pei-KaiHuang/Pei-KaiHuang.github.io/blob/main/poster/2022_BMVC_poster.pdf" style="color:#000000;" >Poster</a> 	  
		</div>
	</td>
	</tr></tbody></table> 
 <br> 
 
 
 <!-- paper 2 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Learning to Augment Face Presentation Attack Dataset via Disentangled Feature Learning from Limited Spoof Data  </i>
			<br>
		    <b>Pei-Kai Huang</b>, Chu-Ling Chang, Hui-Yu Ni, Chiou-Ting Hsu<br>
	  
		  <span style="color: #FF0000;">  IEEE International Conference on Multimedia & Expo (ICME) </span >, 2022, Taipei, Taiwan</a>, [ 
			CCF B]
			<br>
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859657" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV11M411e7YP/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
		| Oral		  
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 
 
 
 	<!-- paper 1 -->
	<table><tbody><tr>
	 
	<td>
		<div align="left">
			<i>Face Anti-Spoofing via Robust Auxiliary Estimation and Discriminative Feature Learning</i>
			<br>
		    <b>Pei-Kai Huang</b>, Ming-Chieh Chin, Chiou-Ting Hsu<br>
	  
                   <span style="color: #FF0000;"> Asian Conference on Pattern Recognition (ACPR) </span > , 2021, Ieju Island, Korea</a>, [Indexed by EI] 
			<br>
		  <a href="https://link.springer.com/chapter/10.1007/978-3-031-02375-0_33" style="color:#000000;">Paper</a> | 
		  <a href="https://www.bilibili.com/video/BV1tx4y1j7Af/?share_source=copy_web&vd_source=6a5816aefc89c8d16c3700c5633c43a9" style="color:#000000;">Video</a>  
		| Oral		
		</div>
	</td>
	</tr></tbody></table> 
 <br>    
 


<a name="Academic Service"><h3>Academic Service</h3></a> 
<hr /> 
 <b>Conference paper reviewer</b>: AAAI26, ICCV25, CVPR25, BMVC25, ICME25, AAAI25, CVPR24, BMVC24, ICCV23, BMVC23, ICIP23, ICME23, ECCV22, CVPR22, BMVC22, ICME22
<br>
<br>  
 <b>Journal paper reviewer</b>:  Scientific Data(Nature family journal) x2, IEEE Transactions on Information Forensics & Security (TIFS) x4 , IEEE Transactions on Instrumentation and Measurement(TIM) x2, IEEE Transactions on Biomedical Engineering (TBME) x1,  IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) x1, Pattern Recognition (PR) x1, 
Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS) x1, Image and Vision Computing x1
<br> 
<br> 
<b>The youth editorial board member</b>: Artificial Intelligence and Autonomous Systems(AIAS), 2025.09-2027.09

</body>
</html>
